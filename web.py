import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from Bio import SeqIO
import io

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score,
    precision_score, recall_score, f1_score
)

# é¡µé¢è®¾ç½®
st.set_page_config(page_title="æŠ—èŒè‚½é¢„æµ‹", layout="wide")
st.title("ğŸ§¬ æŠ—èŒè‚½é¢„æµ‹ç³»ç»Ÿ")
st.markdown("ä¸Šä¼  FASTA æ–‡ä»¶æˆ–è¾“å…¥ä¸€ä¸ªåºåˆ—ï¼Œç³»ç»Ÿå°†æå– AAC ç‰¹å¾å¹¶è¿›è¡ŒæŠ—èŒè‚½é¢„æµ‹ã€‚")

# AAC ç‰¹å¾è®¡ç®—å‡½æ•°
def compute_aac(sequence):
    AA = 'ACDEFGHIKLMNPQRSTVWY'
    count = Counter(sequence)
    seq_len = len(sequence)
    return [count[aa] / seq_len if seq_len > 0 else 0 for aa in AA]

# ä¸Šä¼  FASTA æ–‡ä»¶æˆ–è¾“å…¥åºåˆ—
fasta_file = st.file_uploader("ğŸ“ ä¸Šä¼  FASTA æ–‡ä»¶", type=["fasta", "fa"])
sequence_input = st.text_area("ğŸ”¤ è¾“å…¥ä¸€ä¸ªåºåˆ—è¿›è¡Œé¢„æµ‹", placeholder="è¾“å…¥ä¸€ä¸ªå•ç‹¬çš„æ°¨åŸºé…¸åºåˆ—")

# å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶æˆ–è¾“å…¥çš„åºåˆ—
sequences = []

if fasta_file is not None:
    st.info("âœ… å¼€å§‹è¯»å–åºåˆ—å¹¶æå– AAC ç‰¹å¾...")
    for record in SeqIO.parse(io.StringIO(fasta_file.getvalue().decode()), "fasta"):
        seq = str(record.seq).upper()
        aac = compute_aac(seq)
        sequences.append(aac)

elif sequence_input:
    st.info("âœ… å¼€å§‹å¤„ç†è¾“å…¥çš„å•ä¸ªåºåˆ—...")
    seq = sequence_input.strip().upper()
    aac = compute_aac(seq)
    sequences.append(aac)

if sequences:
    # æ„å»ºæ•°æ®æ¡†å¹¶è®­ç»ƒæ¨¡å‹
    df = pd.DataFrame(sequences, columns=list("ACDEFGHIKLMNPQRSTVWY"))

    # ç‰¹å¾æå–ä¸å»ºæ¨¡
    X = df

    rf = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42)
    rf.fit(X, X)  # è®­ç»ƒæ—¶ä¸éœ€è¦æ ‡ç­¾ï¼Œä½†éœ€è¦æ ¹æ®è‡ªå·±çš„éœ€æ±‚è°ƒæ•´

    feature_importances = pd.Series(rf.feature_importances_, index=X.columns)
    top_10_features = feature_importances.nlargest(10).index.tolist()
    X_selected = X[top_10_features]

    X_train, X_test = train_test_split(X_selected, test_size=0.3, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    best_rf_model = RandomForestClassifier(
        n_estimators=150, max_depth=12, min_samples_split=10,
        min_samples_leaf=4, class_weight='balanced', random_state=42
    )
    best_rf_model.fit(X_train_scaled, X_train)

    # æ¨¡å‹è¯„ä¼°
    st.subheader("ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ")
    st.write(f"æµ‹è¯•é›† Accuracy: {best_rf_model.score(X_test_scaled, X_test):.4f}")

    st.subheader("ğŸ“Œ Precision / Recall / F1")
    st.json({
        "Precision": precision_score(X_test, best_rf_model.predict(X_test), average='weighted'),
        "Recall": recall_score(X_test, best_rf_model.predict(X_test), average='weighted'),
        "F1-score": f1_score(X_test, best_rf_model.predict(X_test), average='weighted'),
    })

    st.subheader("ğŸ§© æ··æ·†çŸ©é˜µ")
    fig, ax = plt.subplots()
    sns.heatmap(confusion_matrix(X_test, best_rf_model.predict(X_test)), annot=True, fmt="d", cmap="Oranges", ax=ax)
    ax.set_title("Test Confusion Matrix")
    st.pyplot(fig)

    st.write("---")
    st.subheader("ğŸ”® é‡æ–°ä¸Šä¼ æ–° FASTA æ–‡ä»¶è¿›è¡Œé¢„æµ‹")
    pred_file = st.file_uploader("ä¸Šä¼ æ–°çš„ FASTA æ–‡ä»¶è¿›è¡ŒæŠ—èŒè‚½é¢„æµ‹", type=["fasta", "fa"], key="predict_fasta")

    def predict_sequence(sequence, model, scaler, selected_features):
        aac = compute_aac(sequence)
        df = pd.DataFrame([aac], columns=list("ACDEFGHIKLMNPQRSTVWY"))
        df_selected = df[selected_features]
        df_scaled = scaler.transform(df_selected)
        prob = model.predict_proba(df_scaled)[0][1]
        pred = model.predict(df_scaled)[0]
        return pred, prob

    if pred_file is not None:
        st.info("æ­£åœ¨åˆ†æå¹¶é¢„æµ‹æ–°åºåˆ—...")
        sequences = []
        for record in SeqIO.parse(io.StringIO(pred_file.getvalue().decode()), "fasta"):
            seq = str(record.seq).upper()
            pred, prob = predict_sequence(seq, best_rf_model, scaler, top_10_features)
            sequences.append({"Name": record.id, "Prediction": pred, "Probability": prob})
        result_df = pd.DataFrame(sequences)
        st.dataframe(result_df)
        st.download_button("ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ", result_df.to_csv(index=False), file_name="prediction_results.csv")

else:
    st.info("è¯·ä¸Šä¼  FASTA æ–‡ä»¶æˆ–è¾“å…¥ä¸€ä¸ªæ°¨åŸºé…¸åºåˆ—è¿›è¡Œé¢„æµ‹ã€‚")
