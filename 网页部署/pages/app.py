import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from Bio import SeqIO
import io

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score,
    precision_score, recall_score, f1_score
)

# È°µÈù¢ËÆæÁΩÆ
st.set_page_config(page_title="ÊäóËèåËÇΩÈ¢ÑÊµã", layout="wide")
st.title("üß¨ ÊäóËèåËÇΩÈ¢ÑÊµãÁ≥ªÁªü")
st.markdown("‰∏ä‰º† FASTA Êñá‰ª∂ÔºåÁ≥ªÁªüÂ∞ÜÊèêÂèñ AAC ÁâπÂæÅÂπ∂ËøõË°åÊäóËèåËÇΩÈ¢ÑÊµã„ÄÇ")

# AAC ÁâπÂæÅËÆ°ÁÆóÂáΩÊï∞
def compute_aac(sequence):
    AA = 'ACDEFGHIKLMNPQRSTVWY'
    count = Counter(sequence)
    seq_len = len(sequence)
    return [count[aa] / seq_len if seq_len > 0 else 0 for aa in AA]

# ‰∏ä‰º† FASTA Êñá‰ª∂
fasta_file = st.file_uploader("üìÅ ‰∏ä‰º† FASTA Êñá‰ª∂ÔºàÂê´Ê†áÁ≠æÊ≥®ÈáäÔºâ", type=["fasta", "fa"])

if fasta_file is not None:
    st.info("‚úÖ ÂºÄÂßãËØªÂèñÂ∫èÂàóÂπ∂ÊèêÂèñ AAC ÁâπÂæÅ...")

    sequences = []
    labels = []

    for record in SeqIO.parse(io.StringIO(fasta_file.getvalue().decode()), "fasta"):
        seq = str(record.seq).upper()
        name = record.id
        # Ë¶ÅÊ±ÇÊ†áÁ≠æÂú®ÊèèËø∞‰∏≠ÔºåÊ†ºÂºèÂ¶Ç ">name|1" Êàñ ">name|0"
        label = int(name.split("|")[-1]) if "|" in name else None
        aac = compute_aac(seq)
        if label is not None:
            sequences.append(aac)
            labels.append(label)

    if not labels:
        st.error("Â∫èÂàóÊ†áÁ≠æÊú™Ê£ÄÊµãÂà∞„ÄÇËØ∑Á°Æ‰øù FASTA Ê†áÈ¢òË°å‰∏∫ `>ÂêçÁß∞|Ê†áÁ≠æ` Ê†ºÂºèÔºå‰æãÂ¶Ç `>seq1|1`„ÄÇ")
    else:
        df = pd.DataFrame(sequences, columns=list("ACDEFGHIKLMNPQRSTVWY"))
        df["label"] = labels

        st.success(f"Â∑≤ËØªÂèñÂ∫èÂàóÊï∞ÈáèÔºö{len(df)}ÔºåÂáÜÂ§áÂª∫Ê®°...")

        # ÁâπÂæÅÊèêÂèñ‰∏éÂª∫Ê®°
        X = df.drop("label", axis=1)
        y = df["label"]

        rf = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42)
        rf.fit(X, y)
        feature_importances = pd.Series(rf.feature_importances_, index=X.columns)
        top_10_features = feature_importances.nlargest(10).index.tolist()
        X_selected = X[top_10_features]

        X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        best_rf_model = RandomForestClassifier(
            n_estimators=150, max_depth=12, min_samples_split=10,
            min_samples_leaf=4, class_weight='balanced', random_state=42
        )
        best_rf_model.fit(X_train_scaled, y_train)

        # Ê®°ÂûãËØÑ‰º∞
        y_test_pred = best_rf_model.predict(X_test_scaled)
        y_test_prob = best_rf_model.predict_proba(X_test_scaled)[:, 1]
        cv_acc = cross_val_score(best_rf_model, X_train_scaled, y_train, cv=5, scoring='accuracy')
        cv_auc = cross_val_score(best_rf_model, X_train_scaled, y_train, cv=5, scoring='roc_auc')

        st.subheader("üìä Ê®°ÂûãËØÑ‰º∞ÁªìÊûú")
        st.write(f"Cross-Validation Accuracy: **{cv_acc.mean():.4f} ¬± {cv_acc.std():.4f}**")
        st.write(f"Cross-Validation AUC: **{cv_auc.mean():.4f} ¬± {cv_auc.std():.4f}**")
        st.write(f"ÊµãËØïÈõÜ Accuracy: {best_rf_model.score(X_test_scaled, y_test):.4f}")
        st.write(f"ÊµãËØïÈõÜ AUC: {roc_auc_score(y_test, y_test_prob):.4f}")

        st.subheader("üìå Precision / Recall / F1")
        st.json({
            "Precision": precision_score(y_test, y_test_pred, average='weighted'),
            "Recall": recall_score(y_test, y_test_pred, average='weighted'),
            "F1-score": f1_score(y_test, y_test_pred, average='weighted'),
        })

        st.subheader("üß© Ê∑∑Ê∑ÜÁü©Èòµ")
        fig, ax = plt.subplots()
        sns.heatmap(confusion_matrix(y_test, y_test_pred), annot=True, fmt="d", cmap="Oranges", ax=ax)
        ax.set_title("Test Confusion Matrix")
        st.pyplot(fig)

        st.write("---")
        st.subheader("üîÆ ÈáçÊñ∞‰∏ä‰º†Êñ∞ FASTA Êñá‰ª∂ËøõË°åÈ¢ÑÊµãÔºà‰∏çÂê´Ê†áÁ≠æÔºâ")
        pred_file = st.file_uploader("‰∏ä‰º†Êñ∞ÁöÑ FASTA Êñá‰ª∂ËøõË°åÊäóËèåËÇΩÈ¢ÑÊµã", type=["fasta", "fa"], key="predict_fasta")

        def predict_sequence(sequence, model, scaler, selected_features):
            aac = compute_aac(sequence)
            df = pd.DataFrame([aac], columns=list("ACDEFGHIKLMNPQRSTVWY"))
            df_selected = df[selected_features]
            df_scaled = scaler.transform(df_selected)
            prob = model.predict_proba(df_scaled)[0][1]
            pred = model.predict(df_scaled)[0]
            return pred, prob

        if pred_file is not None:
            st.info("Ê≠£Âú®ÂàÜÊûêÂπ∂È¢ÑÊµãÊñ∞Â∫èÂàó...")
            sequences = []
            for record in SeqIO.parse(io.StringIO(pred_file.getvalue().decode()), "fasta"):
                seq = str(record.seq).upper()
                name = record.id
                pred, prob = predict_sequence(seq, best_rf_model, scaler, top_10_features)
                sequences.append({"Name": name, "Prediction": pred, "Probability": prob})
            result_df = pd.DataFrame(sequences)
            st.dataframe(result_df)
            st.download_button("üì• ‰∏ãËΩΩÈ¢ÑÊµãÁªìÊûú", result_df.to_csv(index=False), file_name="prediction_results.csv")

else:
    st.info("ËØ∑‰∏ä‰º†Âê´Ê†áÁ≠æÁöÑ FASTA Êñá‰ª∂ËøõË°åËÆ≠ÁªÉÔºå‰æãÂ¶Ç `>seq1|1` Ê†ºÂºè„ÄÇ")
